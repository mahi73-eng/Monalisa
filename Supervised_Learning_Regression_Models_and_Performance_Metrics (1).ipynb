{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose."
      ],
      "metadata": {
        "id": "4tVMk34XFusz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Simple Linear Regression (SLR) is a statistical method used to model the relationship between two continuous variables: a dependent variable (the one you want to predict) and an independent variable (the one you use to predict).\n",
        "\n",
        "Its purpose is to find the best-fitting straight line through the data points, allowing you to understand how changes in the independent variable are associated with changes in the dependent variable, and to make predictions about the dependent variable based on the independent variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "AfWzfVqjFobi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: What are the key assumptions of Simple Linear Regression?"
      ],
      "metadata": {
        "id": "oUXA6bccF2M6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key assumptions of Simple Linear Regression are:\n",
        "\n",
        "Linearity: The relationship between the independent and dependent variables is linear.\n",
        "\n",
        "Independence: The observations are independent of each other.\n",
        "\n",
        "Homoscedasticity: The variance of the errors is constant across all levels of the independent variable.\n",
        "\n",
        "Normality: The errors are normally distributed.\n",
        "\n",
        "No multicollinearity: (Although this is for multiple linear regression, it's worth mentioning as it's a common assumption in regression models) The independent variables are not highly correlated with each other."
      ],
      "metadata": {
        "id": "itywtGJjGAEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3: Write the mathematical equation for a simple linear regression model and explain each term."
      ],
      "metadata": {
        "id": "D_3dNojgGGle"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9037b6a6"
      },
      "source": [
        "The mathematical equation for a simple linear regression model is:\n",
        "\n",
        "$y = \\beta_0 + \\beta_1x + \\epsilon$\n",
        "\n",
        "Where:\n",
        "\n",
        "*   $y$: The dependent variable (the one you are trying to predict).\n",
        "*   $x$: The independent variable (the one you are using to predict).\n",
        "*   $\\beta_0$: The y-intercept, which is the predicted value of $y$ when $x$ is 0.\n",
        "*   $\\beta_1$: The slope of the line, which represents the change in $y$ for a one-unit change in $x$.\n",
        "*   $\\epsilon$: The error term, which represents the random error or the part of $y$ that cannot be explained by the linear relationship with $x$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4: Provide a real-world example where simple linear regression can be applied"
      ],
      "metadata": {
        "id": "IveHqO8xMsGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple linear regression can be applied in many real-world scenarios. One common example is predicting the price of a house based on its size.\n",
        "\n",
        "In this case:\n",
        "\n",
        "Dependent Variable (y): Price of the house\n",
        "Independent Variable (x): Size of the house (e.g., square footage)\n",
        "By collecting data on the prices and sizes of many houses, you could use simple linear regression to find a linear relationship between size and price. This would allow you to:\n",
        "\n",
        "Understand how much the price typically increases for each additional square foot.\n",
        "\n",
        "Predict the price of a new house based on its size.\n",
        "Other examples include:\n",
        "\n",
        "Predicting a student's test score based on the number of hours they studied.\n",
        "Predicting a company's sales based on its advertising expenditure.\n",
        "Predicting the yield of a crop based on the amount of fertilizer used."
      ],
      "metadata": {
        "id": "BQsXyvbkM35V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5: What is the method of least squares in linear regression?"
      ],
      "metadata": {
        "id": "kxzLk3CvNCEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method of least squares is a way to find the best-fitting line in linear regression. It works by minimizing the sum of the squared differences between the actual observed values and the values predicted by the linear model.\n",
        "\n",
        "Imagine you have your data points plotted on a graph. The method of least squares draws a line that is as close as possible to all those points. The \"closeness\" is measured by the vertical distance from each point to the line (the error), and the method aims to make the sum of the squares of these errors as small as possible. This is why it's called \"least squares.\"\n",
        "\n",
        "By minimizing the sum of squared errors, the method of least squares gives you the values for the slope ($\\beta_1$$\\beta_1$) and y-intercept ($\\beta_0$$\\beta_0$) that define the line that best represents the relationship between your variables."
      ],
      "metadata": {
        "id": "nrtULdJPPuii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6: What is Logistic Regression? How does it differ from Linear Regression?"
      ],
      "metadata": {
        "id": "yDmiXhX1Qcug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a statistical method used for binary classification problems, meaning it predicts a categorical outcome with two possible classes (e.g., yes/no, true/false, spam/not spam).\n",
        "\n",
        "Here's how it differs from Linear Regression:\n",
        "\n",
        "Type of Dependent Variable: Linear Regression predicts a continuous dependent variable, while Logistic Regression predicts a categorical dependent variable (specifically, the probability of belonging to a certain class).\n",
        "\n",
        "Output: Linear Regression outputs a continuous value. Logistic Regression outputs a probability (a value between 0 and 1) that can then be used to classify the outcome.\n",
        "\n",
        "Mathematical Function: Linear Regression uses a linear function to model the relationship. Logistic Regression uses a sigmoid function (also known as the logistic function) to map the linear output to a probability between 0 and 1."
      ],
      "metadata": {
        "id": "VaVFZAM6RQDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 7: Name and briefly describe three common evaluation metrics for regression models."
      ],
      "metadata": {
        "id": "GdAUW77nSdTv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5abb1bb8"
      },
      "source": [
        "Here are three common evaluation metrics for regression models:\n",
        "\n",
        "1.  **Mean Absolute Error (MAE):** This is the average of the absolute differences between the predicted values and the actual values. It gives you a sense of the typical magnitude of the errors, without considering their direction.\n",
        "\n",
        "2.  **Mean Squared Error (MSE):** This is the average of the squared differences between the predicted values and the actual values. Squaring the errors penalizes larger errors more heavily than smaller ones.\n",
        "\n",
        "3.  **Root Mean Squared Error (RMSE):** This is the square root of the Mean Squared Error. It is in the same units as the dependent variable, making it easier to interpret than MSE."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 8: What is the purpose of the R-squared metric in regression analysis?"
      ],
      "metadata": {
        "id": "WLRfJSWmSrCM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of the R-squared metric (also known as the coefficient of determination) in regression analysis is to measure the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
        "\n",
        "In simpler terms, it tells you how well the regression model fits the observed data. An R-squared value of 1 means that the model perfectly predicts the dependent variable, while an R-squared value of 0 means that the model does not explain any of the variance in the dependent variable.\n",
        "\n",
        "It's important to note that a high R-squared doesn't necessarily mean the model is good, and a low R-squared doesn't necessarily mean the model is bad. The interpretation of R-squared depends on the specific field of study and the nature of the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "060Ykh2iTfP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept."
      ],
      "metadata": {
        "id": "6oENgGL3Thv_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe83ae53",
        "outputId": "4254851e-3792-47ad-c53b-d2b0ff0900da"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)  # Independent variable\n",
        "y = np.array([2, 4, 5, 4, 5])  # Dependent variable\n",
        "\n",
        "# Create a linear regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the slope and intercept\n",
        "print(\"Slope:\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope: 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10: How do you interpret the coefficients in a simple linear regression model?"
      ],
      "metadata": {
        "id": "xdr_ZXkIT-X1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how you interpret the coefficients in a simple linear regression model ($y = \\beta_0 + \\beta_1x + \\epsilon$$y = \\beta_0 + \\beta_1x + \\epsilon$):\n",
        "\n",
        "Intercept ($\\beta_0$$\\beta_0$): The intercept represents the predicted value of the dependent variable ($y$$y$) when the independent variable ($x$$x$) is zero. However, in many real-world scenarios, an independent variable of zero might not be meaningful or even possible. In such cases, the intercept might not have a practical interpretation, but it's still necessary for defining the regression line.\n",
        "Slope ($\\beta_1$$\\beta_1$): The slope is the most important coefficient in simple linear regression. It represents the change in the predicted value of the dependent variable ($y$$y$) for a one-unit increase in the independent variable ($x$$x$).\n",
        "For example, in the house price example (where $y$$y$ is price and $x$$x$ is size in square feet):\n",
        "\n",
        "The intercept ($\\beta_0$$\\beta_0$) would be the predicted price of a house with zero square feet (which doesn't make sense in reality).\n",
        "The slope ($\\beta_1$$\\beta_1$) would tell you how much the predicted price increases for every additional square foot of the house. If the slope is, say, 150, it means that for every extra square foot, the house price is predicted to increase by $150 (holding other factors constant, which isn't explicitly modeled in simple linear regression).\n",
        "It's crucial to interpret coefficients in the context of your specific problem and data."
      ],
      "metadata": {
        "id": "llKUnkHUUgyZ"
      }
    }
  ]
}